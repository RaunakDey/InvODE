### TODO
- Smarter sampling Sobol, Bayesian opt, CMA-ES optuna, skopt, pyDOE2 
- Local optimization L-BFGS, Nelder-Mead scipy.optimize
- Parallelism Batch evaluation joblib, concurrent.futures
- Gradient methods Adjoint sensitivity jax, torchdiffeq
- Regularization Penalized loss or priors PyMC, NumPyro
- Surrogate modeling GP/RF + active sampling GPyOpt, emukit, skopt
- Caching Hashing parameter dicts Custom or joblib.Memory
- Scaling and reparameterization (eg: log transformed).



 <!--- https://www.threads.com/@aiinminutes/post/DIqoxpYBF60/media --->
